{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSAP course project, Barcelona School of Telecommunication Engineering (ETSETB), UPC\n",
    "# Music Genre Classification using NN methods\n",
    "# Authors: Anatolii Skovitin, Francesco Maccantelli\n",
    "# Year: 2023/2024\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import csv\n",
    "import argparse\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None, num_splits=10):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.classes, self.class_to_idx = self._find_classes(self.root)\n",
    "        self.samples = self._make_dataset(self.root, self.class_to_idx)\n",
    "        self.num_splits = num_splits\n",
    "\n",
    "        # Initialize LabelBinarizer for one-hot encoding\n",
    "        self.label_binarizer = LabelBinarizer()\n",
    "        self.label_binarizer.fit(range(len(self.classes)))\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self, dir, class_to_idx):\n",
    "        dataset = []\n",
    "        for target in sorted(class_to_idx.keys()):\n",
    "            d = os.path.join(dir, target)\n",
    "            if not os.path.isdir(d):\n",
    "                continue\n",
    "\n",
    "            for root, _, fnames in sorted(os.walk(d)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_to_idx[target])\n",
    "                    dataset.append(item)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "\n",
    "        img = np.load(path)\n",
    "\n",
    "        # Use one-hot encoding for the target\n",
    "        target_one_hot = self.label_binarizer.transform([target])[0]\n",
    "\n",
    "        # Ensure that target_one_hot has the correct length (num_classes)\n",
    "        if len(target_one_hot) != 10:\n",
    "            raise ValueError(f\"The length of target_one_hot ({len(target_one_hot)}) does not match num_classes ({10}).\")\n",
    "\n",
    "        # Cast the target label to Long data type\n",
    "        target_one_hot = torch.tensor(target_one_hot, dtype=torch.float32)  # or torch.int64\n",
    "\n",
    "        return img, target_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNtoRNN(nn.Module):\n",
    "    def __init__(self, num_classes, rnn_hidden_size, num_rnn_layers) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, 5, padding=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 5, padding=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Size of the flattened CNN features, needs to be calculated based on the CNN output\n",
    "        self.cnn_output_size = 32 * 160 * 128\n",
    "        # self.cnn_output_size = 1187840\n",
    "\n",
    "        # RNN layers\n",
    "        self.rnn = nn.GRU(input_size=self.cnn_output_size,\n",
    "                          hidden_size=rnn_hidden_size,\n",
    "                          num_layers=num_rnn_layers,\n",
    "                          batch_first=True)\n",
    "\n",
    "        # Linear and LogSoftmax layers\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "        # self.log_softmax = nn.LogSoftmax(dim=-1) # LogSoftmax does not work with CrossEntropyLoss !!!!\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        # Flatten the CNN output for the RNN layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # The RNN layer expects inputs of shape (batch, seq_len, features)\n",
    "        # Since we don't have a sequence, we can treat the entire CNN output as one sequence\n",
    "        # by adding an additional dimension with seq_len=1\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Apply the RNN layer\n",
    "        x, _ = self.rnn(x)\n",
    "\n",
    "        # Take the output for the last time-step\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        # Apply the final fully connected layer and LogSoftmax\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_classes = 10  # Assume there are 10 music genre classes\n",
    "batch_size = 32\n",
    "root = \"data/gtzan/data_MEL_640_b\"  # Replace with the correct path\n",
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 15\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Chose the model to use\n",
    "model_chosen = \"custom_2\"\n",
    "# Choose if doing Train and Test or ONLY TEST\n",
    "num_rnn_layers = 1\n",
    "rnn_hidden_size = 96\n",
    "train = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_info = {\n",
    "    'parameter': 'value',\n",
    "    'lr': f'{learning_rate:.8f}',\n",
    "    'number of epochs': num_epochs,\n",
    "    'base_model': model_chosen,\n",
    "    'device': str(device),\n",
    "    'rnn_hidden_size': 96,\n",
    "    'num_rnn_layers': 1\n",
    "}\n",
    "\n",
    "trained = False\n",
    "\n",
    "# Transformations for spectrogram images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "    \n",
    "dataset = MusicGenreDataset(root, transform=transform)\n",
    "dataset2 = MusicGenreDataset(root, transform=transform)\n",
    "\n",
    "\n",
    "show_first = False\n",
    "if show_first:\n",
    "\n",
    "    # Create a DataLoader\n",
    "    dataloader = torch.utils.data.DataLoader(dataset2, batch_size=25, shuffle=False)\n",
    "\n",
    "    # Iterate over the DataLoader and visualize the first 10 images\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch\n",
    "\n",
    "        for img in images:\n",
    "            print(img.size())\n",
    "\n",
    "        break  # Break after the first batch to show only the first 10 images\n",
    "\n",
    "# Split between training, validation, and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "if model_chosen == \"custom_1\":\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=128, kernel_size=5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),  \n",
    "\n",
    "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),  \n",
    "\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(157 * 29 * 128, 10),\n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )\n",
    "elif model_chosen == \"custom_2\":\n",
    "    \n",
    "    model = CNNtoRNN(num_classes, num_rnn_layers, rnn_hidden_size)\n",
    "    \n",
    "    \n",
    "print(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training and validation loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "if (train):\n",
    "\n",
    "    trained = True\n",
    "\n",
    "    print(\"Trainging on: \", device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\"):\n",
    "            # print(f\"Input shape:{inputs.size()}\")\n",
    "            # print(f\"Labels shape:{labels}\")\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.unsqueeze(1)  # Adds a channel dimension\n",
    "\n",
    "            # print(inputs[0].size())\n",
    "\n",
    "            # HERE = inputs[0]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # print(f\"Output shape:{outputs.size()}\")\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Update this line to use one-hot encoded labels\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "        average_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_losses.append(average_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        model_info[f\"train loss epoch \" + str(epoch)] = f'{average_train_loss:.4f}'\n",
    "        model_info[f\"train accuracy epoch \" + str(epoch)] = f'{train_accuracy:.4f}'\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs_val, labels_val in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "                inputs_val = inputs_val.unsqueeze(1)  # Adds a channel dimension\n",
    "\n",
    "                outputs_val = model(inputs_val)\n",
    "                val_loss = criterion(outputs_val, labels_val)\n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += labels_val.size(0)\n",
    "                correct_val += (predicted_val == torch.argmax(labels_val, dim=1)).sum().item()\n",
    "\n",
    "\n",
    "        average_val_loss = running_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "        val_losses.append(average_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        model_info[f\"val loss epoch \" + str(epoch)] = f'{average_val_loss:.4f}'\n",
    "        model_info[f\"val accuracy epoch \" + str(epoch)] = f'{val_accuracy:.4f}'\n",
    "\n",
    "        # save the model\n",
    "        newpath = \"models/\" + model_chosen + \"_\" + timestr\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "\n",
    "        model_name = str(timestr) + \"_\" + str(epoch) + \".pth\"\n",
    "        # Save the trained model\n",
    "        torch.save(model.state_dict(), 'models/' + model_chosen + \"_\" + timestr + '/' + model_name)\n",
    "\n",
    "        # Print training and validation metrics for the epoch\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "                f\"Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "                f\"Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    model_name = timestr + \".pth\"\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'models/last.pth')\n",
    "\n",
    "    # Plotting the training and validation losses\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting the training and validation accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy', color='blue')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    save_fig_name = timestr + \".png\"\n",
    "    plt.savefig(\"save/\" + model_chosen + \"_\" + save_fig_name)\n",
    "    plt.savefig(\"models/\" + model_chosen + \"_\" + timestr + \"/\" + save_fig_name)\n",
    "    plt.show()\n",
    "\n",
    "# Test the model\n",
    "# Load the saved model state\n",
    "model.load_state_dict(torch.load('models/last.pth'))\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Testing on: \", device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)  # Adds a channel dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Update this line to use one-hot encoded labels\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "        all_predicted.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "model_info[\"accuracy\"] = f'{accuracy:.4f}'\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
    "\n",
    "# Add confusion matrix and F1 score to the model_info dictionary\n",
    "model_info['confusion_matrix'] = conf_matrix.tolist()  # Convert to list for JSON serialization\n",
    "model_info['f1_score'] = f1\n",
    "\n",
    "if trained:\n",
    "    # Save the model information in a CSV file\n",
    "    csv_file_path = \"models/\" + model_chosen + \"_\" + timestr + \"/\" + \"results.csv\"\n",
    "else:\n",
    "    csv_file_path = \"last.csv\"\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for key, value in model_info.items():\n",
    "        # if isinstance(value, list):\n",
    "        #     csv_writer.writerow([key] + value)\n",
    "        # else:\n",
    "        csv_writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
